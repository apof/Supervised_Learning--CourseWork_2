{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import AdaBoost\n",
    "import KernelPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 12000)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"Datasets/Fashion_MNIST_Dataset/fashion-train-imgs.npz\")\n",
    "Y_train = np.load(\"Datasets/Fashion_MNIST_Dataset/fashion-train-labels.npz\")\n",
    "\n",
    "X_valid = np.load(\"Datasets/Fashion_MNIST_Dataset/fashion-dev-imgs.npz\")\n",
    "Y_valid = np.load(\"Datasets/Fashion_MNIST_Dataset/fashion-dev-labels.npz\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "valid_labels = []\n",
    "\n",
    "for label in Y_train:\n",
    "    if(label == 0):\n",
    "        train_labels.append(-1)\n",
    "    else:\n",
    "        train_labels.append(1)\n",
    "        \n",
    "for label in Y_valid:\n",
    "    if(label == 0):\n",
    "        valid_labels.append(-1)\n",
    "    else:\n",
    "        valid_labels.append(1)\n",
    "        \n",
    "train_labels = np.array(train_labels)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "## flatten the 2d images into 1d arrays\n",
    "flat_X_train = []\n",
    "flat_X_valid = []\n",
    "\n",
    "for image in X_train.T:\n",
    "    flat_X_train.append(image.flatten())\n",
    "for image in X_valid.T:\n",
    "    flat_X_valid.append(image.flatten())\n",
    "    \n",
    "train_data = np.array(flat_X_train)[0:1000]\n",
    "valid_data = np.array(flat_X_valid)[0:1000]\n",
    "\n",
    "train_labels = train_labels[0:1000]\n",
    "valid_labels = valid_labels[0:1000]\n",
    "    \n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOOSTING_ROUNDS = 50\n",
    "#model = AdaBoost.AdaBoost()\n",
    "#model.fit(train_data,train_labels,BOOSTING_ROUNDS)\n",
    "#model.plot_learning_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelPerceptron.KernelPerceptron()\n",
    "model.fit(train_data,train_labels,'gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = (model.predict(train_data)[0] != train_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on the trainig set is: 0.018\n"
     ]
    }
   ],
   "source": [
    "print(\"Error on the trainig set is: \" + str(train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_error = (model.predict(valid_data)[0] != valid_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on the validation set is: 0.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Error on the validation set is: \" + str(valid_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.\n",
      " -1.  1.]\n",
      "[2.091914673190354e-18, 1.2199430783829633e-39, 1.550190113065694e-40, -1.793196512284896e-33, -2.1782878124482027e-33, 3.0247215939796982e-27, 3.301588203663697e-33, 2.6747217711829707e-21, 9.07215742844964e-38, 7.9024271046187e-51, 1.0334340642678588e-32, -7.411766915647973e-34, 1.1655981098331464e-31, -9.474606082573542e-58, 4.932715712310776e-47, 1.450548735762528e-54, 3.6190509354012355e-35, 7.893894630010946e-40, -1.1548154818153924e-27, 2.011028740985299e-21]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(valid_data)[0][0:20])\n",
    "print(model.predict(valid_data)[1][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1 -1  1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print(valid_labels[0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
